{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.0-LN-data-correction-and-cleaning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "x1E6t82DOcED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googlemaps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfv5MWyaN1Xk",
        "outputId": "5a050272-5439-4ca9-fd63-372969f0461e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googlemaps\n",
            "  Downloading googlemaps-4.6.0.tar.gz (31 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from googlemaps) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.10)\n",
            "Building wheels for collected packages: googlemaps\n",
            "  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlemaps: filename=googlemaps-4.6.0-py3-none-any.whl size=38554 sha256=71ae91838fa9a8df8ec58f5cc57f1f12f3fef0472d63f31f1cf10df0d1738319\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/db/c0/6d958585fa97b20e250bf437acf7e6e715b4809c2dd4e55367\n",
            "Successfully built googlemaps\n",
            "Installing collected packages: googlemaps\n",
            "Successfully installed googlemaps-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2Vr6phBI38i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import googlemaps\n",
        "import datetime\n",
        "import geopy.distance\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqFzchVzOLBT",
        "outputId": "5fa23747-2abf-469e-8faf-34fea9751503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animalDF = pd.read_excel(\"/content/drive/My Drive/animal_shelter/data/ampa_wmt_rto_hackathon_july-22_data.xlsx\")\n",
        "gmaps = googlemaps.Client(key='AIzaSyBj47Ce7_0rkOTPHZllLAfonfYqu6oW1x0')"
      ],
      "metadata": {
        "id": "chQWwXHPMtP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiprocess Cleaning + Weather Features"
      ],
      "metadata": {
        "id": "5d9kAVU7OZpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Geocoding an address\n",
        "geocode_result = gmaps.geocode('1600 Amphitheatre Parkway, Mountain View, CA')\n",
        "geocode_result[0][\"geometry\"][\"location\"]"
      ],
      "metadata": {
        "id": "KJq11QtAOWxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLngLat(address):\n",
        "    try:\n",
        "        geocode_result = gmaps.geocode(address)\n",
        "\n",
        "        latLngDict = geocode_result[0][\"geometry\"][\"location\"]\n",
        "\n",
        "        return latLngDict[\"lng\"], latLngDict[\"lat\"]\n",
        "    except Exception as e:\n",
        "        print(\"address extract error|\",\"Address：\",address,\"|\", e)\n",
        "\n",
        "        return None, None\n",
        "\n",
        "getLngLat('1600 Amphitheatre Parkway, Mountain View, CA')"
      ],
      "metadata": {
        "id": "YGtRwrLuOeYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_lnglat(name, df, loc_df):\n",
        "    df.index = range(df.shape[0])\n",
        "    ##1.1 crorect coordinates##\n",
        "    for row in tqdm(range(df.shape[0]), desc=f'{name}:'):\n",
        "        for address in ['found_address', 'outcome_address']:\n",
        "            Address = df.loc[row, address]\n",
        "            Address = \" \".join([item for item in Address.split(' ')][:-1]) if type(\n",
        "                Address) == str else Address\n",
        "\n",
        "            lng, lat = getLngLat(Address)\n",
        "\n",
        "            if lng != None and lat != None:\n",
        "                df.loc[row, \"found_lng\"] = lng\n",
        "                df.loc[row, \"found_lat\"] = lat\n",
        "    ##1.2 get distance##\n",
        "    distanceList = []\n",
        "    for row in range(df.shape[0]):\n",
        "        coords_1 = (df.loc[row, \"found_lat\"], df.loc[row, \"found_lng\"])\n",
        "        coords_2 = (df.loc[row, \"outcome_lat\"], df.loc[row, \"outcome_lng\"])\n",
        "        try:\n",
        "            distance = geopy.distance.geodesic(coords_1, coords_2).miles\n",
        "        except Exception as e:\n",
        "            print(f'distance cal error, because:{e}')\n",
        "            distance = 99999\n",
        "        df.loc[row, \"distance\"] = distance\n",
        "\n",
        "    maxColsDict = {\n",
        "        'distance': 10000\n",
        "    }\n",
        "\n",
        "    ###if col's value greater than setted max value, then replace by mean value###\n",
        "    for col, max_val in maxColsDict.items():\n",
        "        index = df[col] > max_val\n",
        "        df.loc[index, col] = round(df.loc[~index, col].mean())\n",
        "    #1.3 get weather info\n",
        "    for row in range(df.shape[0]):\n",
        "        loc, date = df.loc[row, ['shelter_id', 'intake_date']]\n",
        "\n",
        "        this_loc_df = loc_df[loc]\n",
        "        meta_info = this_loc_df[this_loc_df['datetime'] == str(date)]\n",
        "\n",
        "        for attr in ['temp', 'humidity', 'winddir', 'visibility']:\n",
        "            try:\n",
        "                df.loc[row, attr] = meta_info[attr].tolist()[0]\n",
        "            except Exception as e:\n",
        "                df.loc[row, attr] = -1\n",
        "                print(f'no this {date} info, with  {e}')\n",
        "\n",
        "    df = df[df.temp != -1]\n",
        "    df.to_csv(f'{name}.csv', index=False)"
      ],
      "metadata": {
        "id": "B9cKIg8WO-ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_data(save_name, process_num, prefix='process_', remove_sub=True):\n",
        "    df = pd.read_csv(prefix + '0.csv')\n",
        "    for i in range(1, process_num):\n",
        "        next_df = pd.read_csv(prefix + str(i) + '.csv')\n",
        "        df = pd.concat((df, next_df), axis=0, join='inner')\n",
        "        print(df.shape)\n",
        "    if save_name.endswith('xlsx'):\n",
        "        df.to_excel(save_name, index=False)\n",
        "    else:\n",
        "        df.to_csv(save_name, index=False)\n",
        "\n",
        "    if remove_sub:\n",
        "        for i in range(process_num):\n",
        "            os.remove(prefix + str(i) + '.csv')"
      ],
      "metadata": {
        "id": "wdPJ0qaGy3mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    infos = animalDF\n",
        "    infos = infos.dropna()  # drop nan\n",
        "\n",
        "    # reformat address delete space\n",
        "    for col in ['found_address', 'outcome_address']:\n",
        "        infos[col] = infos[col].apply(\n",
        "            lambda x: \" \".join(item.strip() for item in x.split(' ')) if type(x) == str else x)\n",
        "\n",
        "    # get valid lng lat\n",
        "    infos = infos[(infos.found_lng < 180) & (infos.found_lng > -180) &\n",
        "                  (infos.found_lat < 90) & (infos.found_lat > -90)]\n",
        "\n",
        "\n",
        "    def date(para):\n",
        "        if type(para) == int:\n",
        "            delta = pd.Timedelta(str(int(para)) + 'days')\n",
        "            time = pd.to_datetime('1899-12-30') + delta\n",
        "            return time.date()\n",
        "        else:\n",
        "            return para\n",
        "\n",
        "\n",
        "    # get valid time range\n",
        "    infos['intake_date'] = infos['intake_date'].apply(date)\n",
        "\n",
        "    df = infos[infos.intake_date <= datetime.datetime.strptime('2021-12-31', '%Y-%m-%d').date()]\n",
        "\n",
        "    # get extra weather info\n",
        "    locs = set(infos['shelter_id'].tolist())\n",
        "    loc_df = {}\n",
        "    for loc in locs:\n",
        "        loc_df[loc] = pd.read_csv(f'weather_infos/{loc}.csv')\n",
        "\n",
        "    # infos = infos.iloc[5::16, :]\n",
        "    # infos.reindex()\n",
        "\n",
        "    print(f'main process（{os.getpid()}）start...')\n",
        "    process_list = []\n",
        "    prefix = 'process_'\n",
        "    process_num = 16\n",
        "    for i in range(process_num):\n",
        "        part_info = infos.loc[i::process_num, :]\n",
        "        p = Process(target=process_lnglat, args=(prefix + f'{i}', part_info, loc_df,))\n",
        "        process_list.append(p)\n",
        "\n",
        "    for i in range(process_num):\n",
        "        process_list[i].start()\n",
        "\n",
        "    for i in range(process_num):\n",
        "        process_list[i].join()\n",
        "\n",
        "    concat_data('clean_data.csv', process_num, prefix=prefix)"
      ],
      "metadata": {
        "id": "YkV86vi4y8MW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}